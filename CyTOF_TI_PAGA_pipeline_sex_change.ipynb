{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import anndata\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from fcsy import DataFrame\n",
    "import matplotlib\n",
    "from glob import glob\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from igraph import InternalError\n",
    "\n",
    "# scanpy settings\n",
    "sc.settings.verbosity = 0  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=150, frameon=False, figsize=(4, 4)) \n",
    "sc._settings.ScanpyConfig.n_jobs=4 # useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin the information table\n",
    "info_path = 'data/211109_Metadata_GRID_ID.csv'\n",
    "sampleInfo = pd.read_csv(info_path, index_col=0, dtype={'Visit': str})\n",
    "sampleInfo = sampleInfo[sampleInfo['Excluded']!='Yes']\n",
    "sampleInfo = sampleInfo[~sampleInfo['batchGRID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXP-20-CL8796, EXP-21-DG3628, EXP-20-DG3622\n",
    "batch_name = 'DG3622_and_DG3628'\n",
    "selectInfo = sampleInfo[sampleInfo['batchGRID'].isin(['EXP-20-DG3622', 'EXP-21-DG3628'])]\n",
    "selectInfo = selectInfo[selectInfo['Transition']=='FtM']\n",
    "#selectInfo.to_csv('merged_sample_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently working on pDC\n",
      "adata not found, load and preprocess raw data...\n",
      "batch correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'level0' as categorical\n",
      "... storing 'level1' as categorical\n",
      "... storing 'level2' as categorical\n",
      "... storing 'Sample ID' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'Subject ID' as categorical\n",
      "... storing 'group' as categorical\n",
      "... storing 'timepoint_group' as categorical\n",
      "... storing 'batch' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling...\n",
      "write to h5ad file...\n",
      "finished!\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "Cannot remove 1 levels from an index with 1 levels: at least one level must be left.\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on B-cells\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on CD4 T-cells\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on CD8 T-cells\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on Monocytes\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on Neutrophils\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on NK cells\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on Lin Neg\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on gdT\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "Cannot remove 1 levels from an index with 1 levels: at least one level must be left.\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on Plasmablasts\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "Cannot remove 1 levels from an index with 1 levels: at least one level must be left.\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n",
      "currently working on Basophils\n",
      "loading...\n",
      "finished!\n",
      "subsampling...\n",
      "Cannot remove 1 levels from an index with 1 levels: at least one level must be left.\n",
      "calculating PAGA...\n",
      "embedding with FA...\n",
      "embedding with density plot...\n",
      "saving results...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "dataDir = '/Users/tan/cytof_data/*/renamed'\n",
    "labelDir = '/Users/tan/cytof_data/*/classifiedSlim'\n",
    "nsample = 3000\n",
    "#sub_name = 'gdT'\n",
    "\n",
    "drop_columns = ['Time', 'Event_length', '102Pd', '104Pd', '105Pd', '106Pd',\n",
    "                '108Pd', '116Cd', '131Xe', '133Cs', '140Ce', 'DNAIr191',\n",
    "                'DNAIr193', 'Center', 'Offset', 'Width', 'Residual']\n",
    "drop_dic = {'pDC': [], \n",
    "            'B-cells': ['CD33', 'CD3e', 'gdTCR', 'Siglec-8', 'CD14', 'CD141', 'CD4'],\n",
    "            'CD4 T-cells': ['IgD', 'CD1c', 'gdTCR', 'Siglec-8', 'CD20', 'CD14'],\n",
    "            'CD8 T-cells': ['IgD', 'CD11c', 'CD1c', 'gdTCR', 'Siglec-8', 'CD20', 'CD14'],\n",
    "            #'Eosinophils': ['IgD', 'CD57', 'CD25', 'TCRgd', 'CD14'],\n",
    "            'Monocytes': ['CD57', 'IgD', 'CD25', 'CD20', 'gdTCR', 'CD22', 'CD127'], \n",
    "            'Neutrophils': ['IgD', 'HLA-DR', 'CD57', 'CD25', 'CD22', 'gdTCR', 'CD123', 'CD161'],\n",
    "            'NK cells': [],\n",
    "            'Lin Neg': [],\n",
    "            'gdT': [], \n",
    "            'Plasmablasts': [],\n",
    "            'Basophils': []}\n",
    "\n",
    "# readin and merge the file according to \"selectInfo\" as an anndata object\n",
    "all_data_path = 'adata/'+ batch_name +'_sex_change_FtM_no_covariates.h5ad'\n",
    "\n",
    "for sub_name in drop_dic:\n",
    "    print('currently working on ' + sub_name)\n",
    "    if not os.path.exists(all_data_path):\n",
    "        print('adata not found, load and preprocess raw data...')\n",
    "        all_data_list = []\n",
    "        all_label_list = []\n",
    "        for i in range(len(selectInfo)):\n",
    "            label_path = glob(labelDir + '/*/' + str(selectInfo['GRID_ID'].iloc[i]) + '*.csv')[0]\n",
    "            data_path = glob(dataDir + '/*/' + str(selectInfo['GRID_ID'].iloc[i]) + '*.fcs')[0]\n",
    "            labelTmp = pd.read_csv(label_path)\n",
    "            labelTmp['Sample ID'] = np.repeat(selectInfo['Subject'].iloc[i], len(labelTmp.index))\n",
    "            labelTmp['timepoint'] = np.repeat(selectInfo['Visit'].iloc[i], len(labelTmp.index))\n",
    "            labelTmp['Subject ID'] = np.repeat(str(selectInfo['SubjectID'].iloc[i]), len(labelTmp.index))\n",
    "            labelTmp['group'] = np.repeat(str(selectInfo['Transition'].iloc[i]), len(labelTmp.index))\n",
    "            labelTmp['timepoint_group'] = np.repeat(selectInfo['Visit'].iloc[i] + \n",
    "                                                    '_' + \n",
    "                                                    str(selectInfo['Transition'].iloc[i]), len(labelTmp.index))\n",
    "            labelTmp['batch'] = np.repeat(data_path.split('/')[-4], len(labelTmp.index)) #EXP-XX-XXXXXX\n",
    "            dataTmp = DataFrame.from_fcs(data_path, channel_type='long')\n",
    "            if '4-1BB' in set(dataTmp.columns):\n",
    "                dataTmp.rename(columns={\"4-1BB\": \"CD137\"}, inplace=True)\n",
    "            # filter the cells without a level1 tag\n",
    "            dataTmp = dataTmp[labelTmp['level1']!=' ']\n",
    "            labelTmp = labelTmp[labelTmp['level1']!=' ']\n",
    "            # remove EQBeads and DNA channel # also remove the negative channels\n",
    "            dataTmp.drop(columns=drop_columns, inplace=True)\n",
    "            #dataTmp = dataTmp[select_columns]\n",
    "            dataTmp = np.arcsinh(dataTmp/5)\n",
    "            all_data_list.append(dataTmp)\n",
    "            all_label_list.append(labelTmp)\n",
    "\n",
    "        all_data = pd.concat(all_data_list, ignore_index=True)\n",
    "        all_label = pd.concat(all_label_list, ignore_index=True)\n",
    "        adata = anndata.AnnData(all_data)\n",
    "        adata.obs = all_label\n",
    "        print('batch correction...')\n",
    "        #sc.pp.combat(adata, key = 'batch', covariates = ['timepoint'])\n",
    "        sc.pp.combat(adata, key = 'batch')\n",
    "        print('scaling...')\n",
    "        sc.pp.scale(adata)\n",
    "        os.makedirs('adata/', exist_ok=True)\n",
    "        print('write to h5ad file...')\n",
    "        adata.write(filename=all_data_path, compression = 'gzip')\n",
    "        adata=None\n",
    "        print('finished!')\n",
    "    print('loading...')\n",
    "    adata_all = sc.read_h5ad(filename = all_data_path)\n",
    "    print('finished!')\n",
    "\n",
    "\n",
    "    #pd.set_option('display.max_rows', adata_all.obs['Sample ID'].nunique()+1)\n",
    "    #adata_all.obs[adata_all.obs['level2']==sub_name]['Sample ID'].value_counts()\n",
    "\n",
    "    # subsampling\n",
    "    print('subsampling...')\n",
    "    try:\n",
    "        if sub_name in adata_all.obs['level1'].unique().tolist():\n",
    "            sample_index = adata_all.obs[adata_all.obs['level1']==sub_name].groupby('Sample ID').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)\n",
    "        elif sub_name in adata_all.obs['level2'].unique().tolist():\n",
    "            sample_index = adata_all.obs[adata_all.obs['level2']==sub_name].groupby('Sample ID').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)\n",
    "        adata_sample = adata_all[sample_index]\n",
    "    except ValueError as e: \n",
    "        # usually when no file has more cells than nsample and thus no subsampling at all.\n",
    "        # so the results after apply will not be a multiplex index and the droplevel func will fail.\n",
    "        print(e)\n",
    "        if sub_name in adata_all.obs['level1'].unique().tolist():\n",
    "            adata_sample = adata_all[adata_all.obs['level1']==sub_name]\n",
    "        elif sub_name in adata_all.obs['level2'].unique().tolist():\n",
    "            adata_sample = adata_all[adata_all.obs['level2']==sub_name]\n",
    "\n",
    "    adata = anndata.AnnData(adata_sample.to_df().drop(columns = drop_dic[sub_name]))\n",
    "    adata.obs = pd.DataFrame(adata_sample.obs)\n",
    "\n",
    "    # skip\n",
    "    # optimization\n",
    "    #sc.settings.figdir='./optimization/'\n",
    "    #for res in [0.3]:\n",
    "    #    adata_opt = adata\n",
    "    #    n_comps = min([adata_opt.n_obs, adata_opt.n_vars, 21])-1\n",
    "    #    sc.tl.pca(adata_opt, svd_solver='arpack', n_comps=n_comps)\n",
    "    #    sc.pp.neighbors(adata_opt, n_neighbors=10, n_pcs=n_comps)\n",
    "    #    sc.tl.leiden(adata_opt, resolution=res)\n",
    "    #    sc.tl.paga(adata_opt, groups='leiden')\n",
    "    #    sc.pl.paga(adata_opt, color=['leiden'], threshold=0.1, show=False, \n",
    "    #               save='_' + sub_name + '_' + str(res) + '.pdf')\n",
    "    #    adata_opt = []\n",
    "\n",
    "    # save figures to a sub dir\n",
    "    figpath='./figures/' + batch_name + '/' + sub_name + '/'\n",
    "    os.makedirs(figpath, exist_ok=True)\n",
    "    sc.settings.figdir=figpath\n",
    "\n",
    "    print('calculating PAGA...')\n",
    "    #n_comps = min([adata.n_obs, adata.n_vars, 21])-1\n",
    "    #sc.tl.pca(adata, svd_solver='arpack', n_comps=n_comps)\n",
    "    sc.pp.neighbors(adata, n_neighbors=10, use_rep='X')\n",
    "\n",
    "    # paga process\n",
    "    sc.tl.leiden(adata, resolution=0.3) \n",
    "\n",
    "    sc.tl.paga(adata, groups='leiden')\n",
    "    try:\n",
    "        sc.pl.paga(adata, color=['leiden'], threshold=0.1, show=False, \n",
    "                   save='_' + sub_name + '.pdf')\n",
    "    except InternalError as e: # maybe there're too little cells\n",
    "        print(e)\n",
    "        sc.pl.paga(adata, color=['leiden'], show=False, \n",
    "                   save='_' + sub_name + '.pdf')        \n",
    "\n",
    "    print('embedding with FA...')\n",
    "    sc.tl.draw_graph(adata, init_pos='paga')\n",
    "\n",
    "    sc.pl.draw_graph(adata, color=['timepoint', 'group', 'leiden', 'batch', 'Subject ID'], show=False,\n",
    "                     save='_' + sub_name + '.pdf')\n",
    "\n",
    "    sc.pl.draw_graph(adata, color=adata.var.index.values, show=False,\n",
    "                     save='_' + sub_name + '_markers.pdf')\n",
    "\n",
    "    print('embedding with density plot...')\n",
    "\n",
    "    #sc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='group')\n",
    "    #sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_group', \n",
    "    #                        group=['FtM', 'MtF'], show=False, \n",
    "    #                        save='_' + sub_name + '_group_density.pdf')\n",
    "    sc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='timepoint_group')\n",
    "    sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_timepoint_group', \n",
    "                            group=['1_FtM', '2_FtM', '3_FtM'], show=False, \n",
    "                            save='_' + sub_name + '_timepoint_FtM_density.pdf')\n",
    "    #sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_timepoint_group', \n",
    "    #                        group=['1_MtF', '2_MtF', '3_MtF'], show=False, \n",
    "    #                        save='_' + sub_name + '_timepoint_MtF_density.pdf')\n",
    "\n",
    "    print('saving results...')\n",
    "    os.makedirs('PAGA_result_data/'+batch_name+'/', exist_ok=True)\n",
    "    adata.write(filename='PAGA_result_data/'+ batch_name + '/all_' + sub_name + '_sample3000.h5ad', compression = 'gzip')\n",
    "    print('done!')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
